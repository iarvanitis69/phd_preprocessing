#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import numpy as np
from obspy import read, Trace, Stream

#from main import LOG_DIR

#from scipy.stats import pairs



def load_json(path):
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}
    return {}


def save_json(path, data):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)


def insert_channel_result(db_path, event, station, channel, result):
    db = load_json(db_path)

    ev = db.setdefault(event, {})
    st = ev.setdefault(station, {})
    st[channel] = result

    save_json(db_path, db)

def add_station_max_duration_and_min_station_snr(json_path: str, event_name: str, station_name: str, minimun_station_snr:float):
    """
    Î”Î¹Î±Î²Î¬Î¶ÎµÎ¹ Î­Î½Î± JSON Î±ÏÏ‡ÎµÎ¯Î¿ (Ï€.Ï‡. PS_boundaries.json),
    ÎµÎ½Ï„Î¿Ï€Î¯Î¶ÎµÎ¹ Ï„Î¿Î½ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ ÏƒÏ„Î±Î¸Î¼ÏŒ, Ï…Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÎ¹ Ï„Î¿ Î¼Î­Î³Î¹ÏƒÏ„Î¿ duration_time
    ÎºÎ±Î¹ Ï€ÏÎ¿ÏƒÎ¸Î­Ï„ÎµÎ¹ Ï„Î¿ ÎºÎ»ÎµÎ¹Î´Î¯ 'Max Station Duration' ÏƒÏ„Î¿ Î¯Î´Î¹Î¿ ÎµÏ€Î¯Ï€ÎµÎ´Î¿.

    :param json_path: Î Î»Î®ÏÎµÏ‚ path Ï€ÏÎ¿Ï‚ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ JSON
    :param event_name: Î¤Î¿ ÏŒÎ½Î¿Î¼Î± Ï„Î¿Ï… event (Ï€.Ï‡. '20250209T152330_36.60_25.66_7.0km_M3.2')
    :param station_name: Î¤Î¿ ÏŒÎ½Î¿Î¼Î± Ï„Î¿Ï… ÏƒÏ„Î±Î¸Î¼Î¿Ï (Ï€.Ï‡. 'HL.AMGA')
    """
    data = load_json(json_path)

    # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ ÏŒÏ„Î¹ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Ï„Î¿ event ÎºÎ±Î¹ Î¿ ÏƒÏ„Î±Î¸Î¼ÏŒÏ‚
    event_dict = data.get(event_name)
    if event_dict is None:
        print(f"âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï„Î¿ event: {event_name}")
        return

    station_dict = event_dict.get(station_name)
    if station_dict is None:
        print(f"âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î¿ ÏƒÏ„Î±Î¸Î¼ÏŒÏ‚: {station_name}")
        return

    # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î¼Î­Î³Î¹ÏƒÏ„Î·Ï‚ Î´Î¹Î¬ÏÎºÎµÎ¹Î±Ï‚ Î±Ï€ÏŒ Ï„Î± ÎºÎ±Î½Î¬Î»Î¹Î±
    max_duration = 0.0
    for channel, info in station_dict.items():
        if isinstance(info, dict) and "duration_time" in info:
            try:
                dur = float(info["duration_time"])
                if dur > max_duration:
                    max_duration = dur
            except ValueError:
                continue

    # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Ï„Î¿Ï… Î½Î­Î¿Ï… Ï€ÎµÎ´Î¯Î¿Ï…
    station_dict["max_station_duration"] = round(max_duration, 3)
    station_dict["minimun_station_snr"] = round(minimun_station_snr, 3)

    # Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ· Ï„Î¿Ï… JSON
    event_dict[station_name] = station_dict
    data[event_name] = event_dict
    save_json(json_path, data)

    print(f"âœ… Î ÏÎ¿ÏƒÏ„Î­Î¸Î·ÎºÎµ 'ÏƒÏ„Î¿ {station_name} ({event_name}) Max Station Duration': {max_duration:.3f}")


def extract_segment_from_mseed_file(input_path: str, start_index: int, duration_samples: int):
    try:
        st = read(input_path)
        trimmed = st.copy().clear()

        for tr in st:
            end_index = start_index + duration_samples
            if end_index > len(tr.data):
                print(f"âš ï¸ Î ÎµÏÎ¹Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚ end_index ÏƒÏ„Î¿ Î¼Î®ÎºÎ¿Ï‚ Ï„Î¿Ï… trace ({len(tr.data)})")
                end_index = len(tr.data)

            segment = tr.data[start_index:end_index].astype(np.float32)
            if not np.all(np.isfinite(segment)):
                print(f"âš ï¸ ÎœÎ· Î­Î³ÎºÏ…ÏÎµÏ‚ Ï„Î¹Î¼Î­Ï‚ (NaN/Inf) ÏƒÏ„Î¿ {tr.id}")
                return None

            segment = np.clip(segment, -1e12, 1e12)
            seg_trace = tr.copy()
            seg_trace.data = segment
            seg_trace.stats.npts = len(segment)
            seg_trace.stats.starttime += start_index / seg_trace.stats.sampling_rate
            trimmed += seg_trace

        folder = os.path.dirname(input_path)
        base = os.path.basename(input_path).replace(".mseed", "")
        output_filename = f"{base}_PS.mseed"
        output_path = os.path.join(folder, output_filename)

        trimmed.write(output_path, format="MSEED")
        return output_path

    except Exception as e:
        print(f"âŒ Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î¿ extract_segment_from_mseed_file: {e}")
        return None

from typing import List, Set, Tuple

# ==========================================================
# âœ… Î¦Î‘Î£Î— 1: Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ start/pick/end & ÎµÎ½Î·Î¼Î­ÏÏ‰ÏƒÎ· JSON
# ==========================================================
def find_peak_segmentation():
    import os
    import numpy as np
    from obspy import read
    from scipy.signal import find_peaks
    from main import LOG_DIR, BASE_DIR

    OUTPUT_JSON = os.path.join(LOG_DIR, "PS_boundaries.json")
    os.makedirs(LOG_DIR, exist_ok=True)

    snr_path = os.path.join(LOG_DIR, "snr.json")
    if not os.path.exists(snr_path):
        print(f"âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï„Î¿ {snr_path}")
        return set()

    try:
        snr_data = load_json(snr_path)
    except Exception as e:
        print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ Î±Î½Î¬Î³Î½Ï‰ÏƒÎ· Ï„Î¿Ï… snr.json: {e}")
        return set()

    events_dict = snr_data.get("Events", {})

    for year, events in events_dict.items():
        for event, stations in events.items():
            for station, chans in stations.items():
                year_path = os.path.join(BASE_DIR, year)
                event_path = os.path.join(year_path, event)
                station_path = os.path.join(event_path, station)

                for root, _, channels in os.walk(station_path):
                    if "info.json" in root:
                        continue
                    for channel in channels:
                        if not channel.endswith("_demeanDetrend_IC_BPF.mseed"):
                            continue
                        try:
                            st = read(os.path.join(station_path, channel))
                        except Exception as e:
                            print(f"âš ï¸ Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± Î±Î½Î¬Î³Î½Ï‰ÏƒÎ·Ï‚ {channel}: {e}")
                            continue

                        for tr in st:
                            try:
                                data = tr.data.astype(float)
                                sr = tr.stats.sampling_rate
                                aic_idx, aic_curve = aic_picker(data)
                                if aic_idx is None:
                                    print(f"âš ï¸ AIC Î±Ï€Î¿Ï„Ï…Ï‡Î¯Î± Î³Î¹Î± {tr.id}")
                                    continue

                                # --- ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· ---
                                abs_data = np.abs(data)
                                max_val = np.max(abs_data)
                                if max_val == 0:
                                    print(f"âš ï¸ ÎœÎ·Î´ÎµÎ½Î¹ÎºÏŒ ÏƒÎ®Î¼Î± ÏƒÏ„Î¿ {tr.id}")
                                    continue
                                norm_data = abs_data / max_val

                                # --- Î•ÏÏÎµÏƒÎ· Î±ÏÏ‡Î®Ï‚ ---
                                start_time = tr.stats.starttime + aic_idx / sr

                                # --- Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· peaks Î¼ÎµÏ„Î¬ Ï„Î¿ AIC ---
                                search_segment = norm_data[aic_idx + 1:]
                                mean_val = np.mean(search_segment)

                                # Î•Ï†Î¬ÏÎ¼Î¿ÏƒÎµ buffer 0.5s Î¼ÎµÏ„Î¬ Ï„Î¿ AIC Î³Î¹Î± Î½Î± Î±Ï€Î¿Ï†ÏÎ³ÎµÎ¹Ï‚ Î¸ÏŒÏÏ…Î²Î¿
                                buffer_samples = int(0.5 * sr)
                                search_segment = norm_data[aic_idx + buffer_samples:]

                                # ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ threshold Ï€Î¹Î¿ Î±Ï…ÏƒÏ„Î·ÏÎ¿Ï (Ï€.Ï‡. 20% Ï„Î·Ï‚ Î¼Î­Î³Î¹ÏƒÏ„Î·Ï‚ Ï„Î¹Î¼Î®Ï‚)
                                threshold = 0.2 * np.max(search_segment)

                                # Î•ÏÏÎµÏƒÎ· peaks Î¼Îµ ÎµÎ»Î¬Ï‡Î¹ÏƒÏ„Î· Î±Ï€ÏŒÏƒÏ„Î±ÏƒÎ· 0.3s Î¼ÎµÏ„Î±Î¾Ï Ï„Î¿Ï…Ï‚
                                peaks, properties = find_peaks(
                                    search_segment,
                                    height=threshold,
                                    prominence=0.1,
                                    distance=int(0.3 * sr)
                                )

                                if len(peaks) == 0:
                                    pick_idx = int(aic_idx + np.argmax(search_segment))
                                else:
                                    # Î”Î¹Î¬Î»ÎµÎ¾Îµ Ï„Î¿ Ï€Î¹Î¿ Ï…ÏˆÎ·Î»ÏŒ peak, ÏŒÏ‡Î¹ Ï„Î¿ Ï€ÏÏÏ„Î¿
                                    main_peak = peaks[np.argmax(properties["peak_heights"])]
                                    pick_idx = aic_idx + buffer_samples + main_peak

                                pick_time = tr.stats.starttime + pick_idx / sr
                                pick_ampl = float(norm_data[pick_idx])  # normalized amplitude

                                # --- ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ Ï„Î­Î»Î¿Ï…Ï‚ Ï„Î¼Î®Î¼Î±Ï„Î¿Ï‚ ---
                                end_idx = 2 * pick_idx - aic_idx
                                end_time = tr.stats.starttime + end_idx / sr
                                duration_samples = int(2 * (pick_idx - aic_idx))
                                duration_time = duration_samples / sr

                                ch_id = tr.id.split('.')[-1]

                                insert_channel_result(
                                    OUTPUT_JSON,
                                    os.path.basename(event_path),
                                    os.path.basename(station_path),
                                    ch_id,
                                    {
                                        "start_idx": int(aic_idx),
                                        "start_time": str(start_time),
                                        "peak_amplitude_idx": int(pick_idx),
                                        "peak_amplitude_time": str(pick_time),
                                        "peak_amplitude": pick_ampl,
                                        "end_of_peak_segment_sample": int(end_idx),
                                        "end_of_peak_segment_time": str(end_time),
                                        "duration_nof_samples": duration_samples,
                                        "duration_time": str(duration_time),
                                    },
                                )

                                print(f"âœ… {os.path.basename(event_path)}/{os.path.basename(station_path)}/{tr.id}: {start_time} â†’ {end_time}")

                            except Exception as e:
                                print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î¿ {os.path.basename(event_path)}/{os.path.basename(station_path)}/{tr.id}: {e}")

                # --- Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ· SNR ÎºÎ±Î¹ Î´Î¹Î¬ÏÎºÎµÎ¹Î±Ï‚ ---
                add_station_max_duration_and_min_station_snr(
                    OUTPUT_JSON,
                    os.path.basename(event_path),
                    os.path.basename(station_path),
                    chans.get("minimum_snr", 0),
                )

    print(f"\nğŸ’¾ Î‘Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎ±Î½ ÏƒÏ„Î¿: {OUTPUT_JSON}")


# ==========================================================
# âœ… Î¦Î‘Î£Î— 2: Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î±Ï€Î¿ÏƒÏ€Î±ÏƒÎ¼Î¬Ï„Ï‰Î½ Î¼Îµ ÏƒÏ„Î±Î¸ÎµÏÏŒ duration
# ==========================================================
def create_peak_segmentation_files():
    from main import LOG_DIR, BASE_DIR
    OUTPUT_JSON = os.path.join(LOG_DIR, "event_boundaries.json")
    db = load_json(OUTPUT_JSON)

    max_duration = float(db.get("maximum_duration_time", 0.0))
    if max_duration <= 0:
        print("âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î­Î³ÎºÏ…ÏÎ¿ Î¼Î­Î³Î¹ÏƒÏ„Î¿ duration.")
        return

    duration_samples = None

    for root, _, files in os.walk(BASE_DIR):
        if "Logs" in root:
            continue
        for file in files:
            if not file.endswith("_demeanDetrend_IC_BPF_PS.mseed"):
                continue

            file_path = os.path.join(root, file)
            try:
                st = read(file_path)
            except Exception as e:
                print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬Î³Î½Ï‰ÏƒÎ·Ï‚ {file_path}: {e}")
                continue

            for tr in st:
                event_name = os.path.normpath(file_path).split(os.sep)[-3]
                station_name = os.path.normpath(file_path).split(os.sep)[-2]
                ch_id = tr.id.split('.')[-1]

                start_idx = int(db.get(event_name, {})
                                   .get(station_name, {})
                                   .get(ch_id, {})
                                   .get("start_idx", -1))

                if start_idx < 0:
                    continue

                sr = tr.stats.sampling_rate
                if duration_samples is None:
                    duration_samples = int(round(max_duration * sr))

                output_path = extract_segment_from_mseed_file(
                    input_path=file_path,
                    start_index=start_idx,
                    duration_samples=duration_samples
                )

                if output_path:
                    print(f"âœ… Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎµ: {output_path}")

def aic_picker(trace_data):
    """
    Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÎ¹ Ï„Î¿ AIC ÏƒÎµ Î¿Î»ÏŒÎºÎ»Î·ÏÎ¿ Ï„Î¿ ÏƒÎ®Î¼Î± (Î¼Î­Ï‡ÏÎ¹ Ï„Î¿ pick) ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹
    Ï„Î¿ index ÏŒÏ€Î¿Ï… ÎµÎ»Î±Ï‡Î¹ÏƒÏ„Î¿Ï€Î¿Î¹ÎµÎ¯Ï„Î±Î¹, Ï‰Ï‚ Ï€Î¹Î¸Î±Î½Î® Î­Î½Î±ÏÎ¾Î· Ï„Î¿Ï… ÏƒÎµÎ¹ÏƒÎ¼Î¹ÎºÎ¿Ï ÎºÏÎ¼Î±Ï„Î¿Ï‚.

    :param trace_data: numpy array Î¼Îµ Ï„Î¿ ÏƒÎµÎ¹ÏƒÎ¼Î¹ÎºÏŒ ÏƒÎ®Î¼Î± (float, demeaned)
    :return: (index_Î­Î½Î±ÏÎ¾Î·Ï‚, ÎºÎ±Î¼Ï€ÏÎ»Î·_AIC)
    """
    data = trace_data.astype(float)
    n = len(data)
    if n < 3:
        return None, np.array([])

    pick_idx = int(np.argmax(np.abs(data)))  # Î¼Î­Î³Î¹ÏƒÏ„Î· Î±Ï€ÏŒÎ»Ï…Ï„Î· Ï„Î¹Î¼Î®
    if pick_idx < 10:
        return None, np.array([])  # Ï€Î¿Î»Ï Î¼Î¹ÎºÏÏŒ ÏƒÎ®Î¼Î±

    aic = np.zeros(pick_idx)

    for k in range(1, pick_idx - 1):
        var1 = np.var(data[:k]) or 1e-10
        var2 = np.var(data[k:pick_idx]) or 1e-10
        aic[k] = k * np.log(var1) + (pick_idx - k - 1) * np.log(var2)

    min_idx = int(np.argmin(aic[1:pick_idx - 1])) + 1
    return min_idx, aic

import matplotlib.pyplot as plt

def plot_station_duration_distribution(bin_size: float = 10.0, output_png: str = None):
    """
    Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÎ¹ ÎºÎ±Î¹ ÏƒÏ‡ÎµÎ´Î¹Î¬Î¶ÎµÎ¹ Ï„Î·Î½ ÎºÎ±Ï„Î±Î½Î¿Î¼Î® (ÏÎ±Î²Î´ÏŒÎ³ÏÎ±Î¼Î¼Î±)
    Ï„Ï‰Î½ Max Station Duration Ï„Î¹Î¼ÏÎ½ Î±Ï€ÏŒ Ï„Î¿ JSON.

    :param json_path: Î Î»Î®ÏÎµÏ‚ path Ï€ÏÎ¿Ï‚ Ï„Î¿ PS_boundaries.json
    :param bin_size: Î•ÏÏÎ¿Ï‚ bin (ÏƒÎµ Î´ÎµÏ…Ï„ÎµÏÏŒÎ»ÎµÏ€Ï„Î±)
    :param output_png: Î‘Î½ Î´Î¿Î¸ÎµÎ¯ path, ÏƒÏÎ¶ÎµÎ¹ Ï„Î¿ Î´Î¹Î¬Î³ÏÎ±Î¼Î¼Î± ÏƒÎµ PNG
    """
    data = load_json(OUTPUT_JSON)
    durations = []

    # --- Î’Î®Î¼Î± 1: Î£Ï…Î»Î»Î¿Î³Î® ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ max_station_duration ---
    for event_name, stations in data.items():
        for station_name, channels in stations.items():
            if not isinstance(channels, dict):
                continue
            max_dur = channels.get("max_station_duration")
            if max_dur is None:
                continue
            try:
                durations.append(float(max_dur))
            except ValueError:
                continue

    if not durations:
        print("âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Ï„Î¹Î¼Î­Ï‚ max_station_duration")
        return

    # --- Î’Î®Î¼Î± 2: Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± bins ---
    max_value = max(durations)
    bins = np.arange(0, max_value + bin_size, bin_size)

    # --- Î’Î®Î¼Î± 3: Î£Ï‡ÎµÎ´Î¯Î±ÏƒÎ· ÏÎ±Î²Î´Î¿Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚ ---
    plt.figure(figsize=(10, 6))
    plt.hist(durations, bins=bins, color="steelblue", edgecolor="black", alpha=0.8)

    plt.title("ÎšÎ±Ï„Î±Î½Î¿Î¼Î® Max Station Duration", fontsize=14, fontweight="bold")
    plt.xlabel("Î”Î¹Î¬ÏÎºÎµÎ¹Î± ÏƒÏ„Î±Î¸Î¼Î¿Ï (Î´ÎµÏ…Ï„ÎµÏÏŒÎ»ÎµÏ€Ï„Î±)", fontsize=12)
    plt.ylabel("Î Î»Î®Î¸Î¿Ï‚ ÏƒÏ„Î±Î¸Î¼ÏÎ½", fontsize=12)
    plt.grid(axis="y", linestyle="--", alpha=0.6)

    # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Ï„Ï‰Î½ labels Ï€Î¬Î½Ï‰ Î±Ï€ÏŒ Ï„Î¹Ï‚ Î¼Ï€Î¬ÏÎµÏ‚
    counts, _, patches = plt.hist(durations, bins=bins)
    for c, p in zip(counts, patches):
        if c > 0:
            plt.text(p.get_x() + p.get_width()/2, c, f"{int(c)}", ha="center", va="bottom", fontsize=9)

    plt.tight_layout()

    # --- Î’Î®Î¼Î± 4: Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î® ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ· ---
    if output_png:
        plt.savefig(output_png, dpi=200)
        print(f"ğŸ’¾ Î‘Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ Ï„Î¿ ÏÎ±Î²Î´ÏŒÎ³ÏÎ±Î¼Î¼Î± ÏƒÏ„Î¿ {output_png}")
    else:
        plt.show()

# ==========================================================
if __name__ == "__main__":
    find_peak_segmentation()
    #create_peak_segmentation_files()
