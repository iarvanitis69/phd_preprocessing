import os
import json
import numpy as np
from obspy import read, Trace
import shutil

from concurrent.futures import ProcessPoolExecutor, as_completed

def extract_event_info(event_folder_name: str):
    """
    Î .Ï‡. '20100507T041515_36.68_25.71_15.0km_M3.4'
    Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ dict Î¼Îµ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ ÏƒÎµÎ¹ÏƒÎ¼Î¹ÎºÎ¿Ï Î³ÎµÎ³Î¿Î½ÏŒÏ„Î¿Ï‚.
    """
    try:
        parts = event_folder_name.split("_")
        origin_time = parts[0]
        lat = parts[1]
        lon = parts[2]
        depth = parts[3].replace("km", "")
        mag = parts[4].replace("M", "")
        return {
            "event_folder": event_folder_name,
            "origin_time": origin_time,
            "latitude": float(lat),
            "longitude": float(lon),
            "depth_km": float(depth),
            "magnitude": float(mag)
        }
    except Exception:
        return {
            "event_folder": event_folder_name,
            "origin_time": None,
            "latitude": None,
            "longitude": None,
            "depth_km": None,
            "magnitude": None
        }

def find_glitches(trace: Trace, threshold, window_size: int = 2):
    """
    Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î»Î¯ÏƒÏ„Î± Î±Ï€ÏŒ glitches Ï€Î¿Ï… ÎµÎ½Ï„Î¿Ï€Î¯ÏƒÏ„Î·ÎºÎ±Î½ ÏƒÏ„Î¿ trace.
    """
    data = trace.data.astype(float)
    max_val = np.max(np.abs(data))
    if max_val == 0:
        return []

    data /= max_val
    glitches = []

    for i in range(len(data) - 2 * window_size):
        win1 = data[i:i + window_size]
        win2 = data[i + window_size:i + 2 * window_size]
        d1 = np.diff(win1)
        d2 = np.diff(win2)

        peak_rise = np.max(d1)
        peak_fall = np.min(d2)

        # Î†Î½Î¿Î´Î¿Ï‚ Î±ÎºÎ¿Î»Î¿Ï…Î¸Î¿ÏÎ¼ÎµÎ½Î· Î±Ï€ÏŒ ÎºÎ¬Î¸Î¿Î´Î¿
        if peak_rise > threshold and peak_fall < -threshold:
            glitches.append({
                "start_index": i,
                "end_index": i + 2 * window_size,
                "channel": trace.stats.channel,
                "station": trace.stats.station,
                "start_time": str(trace.stats.starttime + i / trace.stats.sampling_rate),
                "end_time": str(trace.stats.starttime + (i + 2 * window_size) / trace.stats.sampling_rate),
                "peak_rise": round(peak_rise, 4),
                "peak_fall": round(peak_fall, 4)
            })
    return glitches

def find_files_for_glitches_parallel(threshold: float = 1.0, max_workers: int = 4):
    """
    Î•ÎºÏ„ÎµÎ»ÎµÎ¯ Ï€Î±ÏÎ¬Î»Î»Î·Î»Î· ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î³ÎµÎ³Î¿Î½ÏŒÏ„Ï‰Î½ ÎºÎ±Î¹ Î³ÏÎ¬Ï†ÎµÎ¹ Î¬Î¼ÎµÏƒÎ± Ï„Î± glitches ÏƒÏ„Î¿ JSON.
    """
    from main import BASE_DIR
    print(f"ğŸš€ ÎˆÎ½Î±ÏÎ¾Î· ÏƒÎ¬ÏÏ‰ÏƒÎ·Ï‚ ÏƒÏ„Î¿: {BASE_DIR}")

    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        futures = []
        for year in sorted(os.listdir(BASE_DIR)):
            year_path = os.path.join(BASE_DIR, year)
            if not os.path.isdir(year_path) or year == "Logs":
                continue

            for event in sorted(os.listdir(year_path)):
                event_path = os.path.join(year_path, event)
                if not os.path.isdir(event_path):
                    continue

                futures.append(executor.submit(process_single_event, event_path, threshold))

        for f in as_completed(futures):
            print(f.result())

    print("ğŸ’¾ ÎŒÎ»Î± Ï„Î± glitches Î­Ï‡Î¿Ï…Î½ Î®Î´Î· Î³ÏÎ±Ï†Ï„ÎµÎ¯ ÏƒÏ„Î¿ Logs/glitches.json.")

def process_single_event(event_path: str, threshold: float):
    """
    Î•Ï€ÎµÎ¾ÎµÏÎ³Î¬Î¶ÎµÏ„Î±Î¹ Î­Î½Î± ÏƒÎµÎ¹ÏƒÎ¼Î¹ÎºÏŒ Î³ÎµÎ³Î¿Î½ÏŒÏ‚ ÎºÎ±Î¹ Î³ÏÎ¬Ï†ÎµÎ¹ ÎºÎ¬Î¸Îµ glitch
    Î¬Î¼ÎµÏƒÎ± ÏƒÏ„Î¿ glitches.json Î¼Îµ Ï„Î¿ Î½Î­Î¿ format.
    """
    event_info = extract_event_info(os.path.basename(event_path))
    event_name = event_info["event_folder"]
    for station in sorted(os.listdir(event_path)):
        station_path = os.path.join(event_path, station)
        mseed_path = os.path.join(station_path, "mseed")
        if not os.path.isdir(mseed_path):
            continue

        for fname in os.listdir(mseed_path):
            if not fname.endswith(".mseed"):
                continue

            full_path = os.path.join(mseed_path, fname)
            try:
               st = read(full_path)
               for tr in st:
                   glitches = find_glitches(tr, threshold=threshold)
                   if glitches:
                        for g in glitches:
                            g["file"] = fname
                        station_id = f"{tr.stats.network}.{tr.stats.station}"
                        append_to_json_file(event_name, station_id, tr.stats.channel, glitches)
                        print(
                            f"ğŸ“ˆ {event_name} | {tr.stats.station} | {tr.stats.channel} | {len(glitches)} glitches")
            except Exception as e:
                print(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ {fname}: {e}")

    return f"âœ… ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ: {event_name}"

def append_to_json_file(event_name, station, channel, glitches):
    """
    Î ÏÎ¿ÏƒÎ¸Î­Ï„ÎµÎ¹ Ï„Î± glitches ÎµÎ½ÏŒÏ‚ ÎºÎ±Î½Î±Î»Î¹Î¿Ï Î¼Î­ÏƒÎ± ÏƒÏ„Î¿ Logs/glitches.json
    ÏƒÏ„Î¿ ÏƒÏ‰ÏƒÏ„ÏŒ format:
    event â†’ station â†’ channel â†’ {count, glitches: [...]}
    """
    from main import BASE_DIR
    logs_path = os.path.join(BASE_DIR, "Logs")
    os.makedirs(logs_path, exist_ok=True)
    output_file = os.path.join(logs_path, "glitches.json")
    import multiprocessing
    lock = multiprocessing.Manager().Lock()
    with lock:
        # Î”Î¹Î¬Î²Î±ÏƒÎ¼Î± Ï…Ï€Î¬ÏÏ‡Î¿Î½Ï„Î¿Ï‚ JSON (Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹)
        if os.path.exists(output_file):
            with open(output_file, "r", encoding="utf-8") as f:
               try:
                   data = json.load(f)
               except json.JSONDecodeError:
                   data = {}
        else:
            data = {}

        # --- Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ· Î´Î¿Î¼Î®Ï‚ ---
        if event_name not in data:
            data[event_name] = {}
        if station not in data[event_name]:
            data[event_name][station] = {}
        if channel not in data[event_name][station]:
            data[event_name][station][channel] = {"count": 0, "glitches": []}

        # --- Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Î½Î­Ï‰Î½ glitches ---
        data[event_name][station][channel]["glitches"].extend(glitches)
        data[event_name][station][channel]["count"] += len(glitches)
        # --- Î•Î³Î³ÏÎ±Ï†Î® ÏƒÏ„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ ---
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

def delete_files_with_glitches():
    """
    Î”Î¹Î±Î³ÏÎ¬Ï†ÎµÎ¹ ÏŒÎ»Î¿Ï…Ï‚ Ï„Î¿Ï…Ï‚ ÏƒÏ„Î±Î¸Î¼Î¿ÏÏ‚ Ï€Î¿Ï… Î­Ï‡Î¿Ï…Î½ glitches ÏƒÎµ Ï„Î¿Ï…Î»Î¬Ï‡Î¹ÏƒÏ„Î¿Î½ Î­Î½Î± channel.
    Î‘Î½ Î¼ÎµÏ„Î¬ Ï„Î· Î´Î¹Î±Î³ÏÎ±Ï†Î® Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÎºÎ±Î½Î­Î½Î±Ï‚ ÏƒÏ„Î±Î¸Î¼ÏŒÏ‚ ÏƒÏ„Î¿ event, Î´Î¹Î±Î³ÏÎ¬Ï†ÎµÏ„Î±Î¹ ÎºÎ±Î¹ Ï„Î¿ event.
    """
    from main import BASE_DIR

    glitches_path = os.path.join(BASE_DIR, "Logs", "glitches.json")
    if not os.path.exists(glitches_path):
        print(f"[âœ˜] Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿: {glitches_path}")
        return

    with open(glitches_path, "r", encoding="utf-8") as f:
        try:
            glitches_data = json.load(f)
        except json.JSONDecodeError:
            print("[âœ˜] Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ glitches.json ÎµÎ¯Î½Î±Î¹ Î¬Î´ÎµÎ¹Î¿ Î® ÎºÎ±Ï„ÎµÏƒÏ„ÏÎ±Î¼Î¼Î­Î½Î¿.")
            return

    deleted_stations = 0
    deleted_events = 0

    for event, stations in glitches_data.items():
        year = event[:4]
        event_path = os.path.join(BASE_DIR, year, event)

        for station in stations.keys():
            station_path = os.path.join(event_path, station)
            if os.path.isdir(station_path):
                try:
                    shutil.rmtree(station_path)
                    print(f"[Î”Î™Î‘Î“Î¡Î‘Î¦Î—] {year}/{event}/{station} (Î»ÏŒÎ³Ï‰ glitch)")
                    deleted_stations += 1
                except Exception as e:
                    print(f"[Î£Î¦Î‘Î›ÎœÎ‘] Î”ÎµÎ½ Î´Î¹Î±Î³ÏÎ¬Ï†Î·ÎºÎµ Î¿ ÏƒÏ„Î±Î¸Î¼ÏŒÏ‚ {station_path}: {e}")

        # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Î±Ï€Î­Î¼ÎµÎ¹Î½Îµ ÎºÎ¬Ï„Î¹ ÏƒÏ„Î¿ event
        if os.path.isdir(event_path) and len(os.listdir(event_path)) == 0:
            try:
                shutil.rmtree(event_path)
                print(f"[Î”Î™Î‘Î“Î¡Î‘Î¦Î— EVENT] {year}/{event} (ÎºÎµÎ½ÏŒ Î¼ÎµÏ„Î¬ Î±Ï€ÏŒ Î´Î¹Î±Î³ÏÎ±Ï†Î­Ï‚)")
                deleted_events += 1
            except Exception as e:
                print(f"[Î£Î¦Î‘Î›ÎœÎ‘] Î”ÎµÎ½ Î´Î¹Î±Î³ÏÎ¬Ï†Î·ÎºÎµ Ï„Î¿ event {event_path}: {e}")

    print(f"\n[âœ”] ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ: {deleted_stations} ÏƒÏ„Î±Î¸Î¼Î¿Î¯ Î´Î¹Î±Î³ÏÎ¬Ï†Î·ÎºÎ±Î½, {deleted_events} ÎºÎµÎ½Î¬ events Î´Î¹Î±Î³ÏÎ¬Ï†Î·ÎºÎ±Î½.")
